---
title: 'DGM: A deep learning algorithm for solving partial differential equations'
date: 2023-11-17
permalink: /posts/dgm
excerpt: "A blog post on the paper <i>'DGM: A deep learning algorithm for solving partial differential equations'</i> by Justin Sirignano and Konstantinos Spiliopoulos, published in 2018."
categories: 
  - Blog Posts
tags:
  - Deep Learning 
  - Machine Learning
  - Partial Differential Equation
---

Partial Differential Equations (PDEs) play a crucial role in modeling various phenomena in physics, engineering, and finance. Solving high-dimensional PDEs has been a longstanding computational challenge, with traditional methods becoming impractical due to the explosion in the number of grid points and the demand for reduced time step size. In this blog post, we explore the approach from the paper *'DGM: A deep learning algorithm for solving partial differential equations'* by Justin Sirignano and Konstantinos Spiliopoulos, published in 2018 called the Deep Galerkin Method (DGM) that leverages deep learning to efficiently solve high-dimensional PDEs.

## TL;DR
High-dimensional PDEs, with multiple spatial dimensions, pose a computational challenge due to the impracticality of using traditional finite difference methods. The mesh size grows exponentially with the number of dimensions, making it computationally intractable. The paper proposes a mesh-free approach using deep neural networks to approximate solutions, mitigating the challenges associated with traditional methods.

The Deep Galerkin Method (DGM) is a mesh-free algorithm inspired by the Galerkin method, a widely-used computational technique for solving PDEs. However, instead of representing the solution as a linear combination of basis functions, DGM employs a deep neural network. The neural network is trained to satisfy the differential operator, initial conditions, and boundary conditions using stochastic gradient descent on randomly sampled spatial points.

The authors present promising numerical results for DGM on a class of high-dimensional free boundary PDEs, demonstrating its accuracy in solving problems up to 200 dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE and Burgers' equation, showcasing its versatility and robustness.

To address the computational cost associated with calculating second derivatives in higher dimensions, the paper introduces a modified algorithm using a Monte Carlo method. This approach significantly reduces computational expenses while introducing some bias and variance. The trade-off between computational efficiency and accuracy is carefully considered.

## Introduction

- PDEs, Motivation
- Usual approaches, problems with high number of dimensions
- New approach with Deep Learning
- Galerkin Method -> Deep Galerkin Method (DGM)

## Partial Differential Equations
- a

## The Galerkin Method
- a

## Stochastic Gradient Descent
- a

## The algorithm

- Define (general) PDE
- Define deep neural network with parameters $$\theta$$
- Algorithm:
  - Draw random points $$s_n$$
  - Define error function $$G(\theta_n, s_n)$$
  - Take descent steps until convergence: $$\theta_{n+1}= \theta_{n} - \alpha_n \nabla_{\theta}G(\theta_n, s_n)$$

- Show correctness

### Monte Carlo 2nd derivatives

- Problem with computation of second derivatives
- Describe Monte Carlo approach for fast computation of 2nd derivatives
- Show approximation bias, approximation error 
- Describe the modified algorithm

## Numerical Analysis

Here we discuss the numerical results of the algorithm.

The algorithm is tested on
- High-dimensional Free Boundary PDE
- High-dimensional Hamilton-Jacobi-Bellman PDE
- Burgersâ€™ equation

The discussion of the experiments is structured as 
- Define the PDE
- Adjust the algorithm to the specific problem
- Implementation details
- Results

## Neural Network Approximation Theorem for PDEs

In progress

## Conclusion

In progress

## References

- Sirignano, J., Spiliopoulos, K. (2018). *DGM: A deep learning algorithm for solving partial differential equations*. [arXiv: 1708.07469](https://arxiv.org/abs/1708.07469)
