---
title: 'DGM: A deep learning algorithm for solving partial differential equations'
date: 2023-11-17
permalink: /posts/dgm
excerpt: "A blog post on the paper <i>'DGM: A deep learning algorithm for solving partial differential equations'</i> by Justin Sirignano and Konstantinos Spiliopoulos, published in 2018."
categories: 
  - Blog Posts
tags:
  - Deep Learning 
  - Machine Learning
  - Partial Differential Equation
---

[Version 1]

Partial Differential Equations (PDEs) play a crucial role in modeling various phenomena in physics, engineering, and finance. Solving high-dimensional PDEs has been a longstanding computational challenge, with traditional methods becoming impractical due to the explosion in the number of grid points and the demand for reduced time step size.

In this blog post, I explore the approach from the paper *'DGM: A deep learning algorithm for solving partial differential equations'* by Justin Sirignano and Konstantinos Spiliopoulos, published in 2018 called the Deep Galerkin Method (DGM) that leverages deep learning to efficiently solve high-dimensional PDEs. 

## TL;DR
High-dimensional PDEs, with multiple spatial dimensions, pose a computational challenge due to the impracticality of using traditional mesh-based finite difference methods. The mesh size grows exponentially with the number of dimensions, making it computationally intractable. The paper proposes a mesh-free approach using a deep neural network to approximate a solution, mitigating the challenges associated with traditional methods.

The Deep Galerkin Method (DGM) is a mesh-free algorithm inspired by the Galerkin method, a widely-used computational technique for solving PDEs. However, instead of representing the solution as a linear combination of basis functions, the DGM employs a deep neural network. The neural network is trained to satisfy the differential operator, initial conditions, and boundary conditions using stochastic gradient descent on randomly sampled spatial points.

The authors present promising numerical results for the DGM on a class of high-dimensional free boundary PDEs, demonstrating its accuracy in solving problems up to 200 dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE and Burgers' equation, showcasing its versatility and robustness.

To address the computational cost associated with calculating second derivatives in higher dimensions, the paper introduces a modified algorithm using a Monte Carlo method. This approach significantly reduces computational expenses while introducing some bias and variance. The trade-off between computational efficiency and accuracy is carefully considered.

In conclusion, by combining insights from machine learning and numerical methods, the Deep Galerkin Method opens new possibilities for tackling complex high-dimensional PDEs in various scientific and engineering domains.

## Introduction
Addressing the computational hurdles posed by high-dimensional Partial Differential Equations (PDEs) that involve multiple spatial dimensions is a challenging task. Traditional mesh-based finite difference methods become impractical in such scenarios, as the mesh size grows exponentially with the increasing number of dimensions, rendering computations intractable. In response to this challenge, the paper introduces an innovative solution that embraces a mesh-free approach, leveraging the power of deep neural networks to approximate solutions and alleviate the limitations associated with conventional methods.

At the core of this approach is the Deep Galerkin Method (DGM), a mesh-free algorithm inspired by the well-established Galerkin method, widely employed in computational techniques for solving PDEs. Diverging from the conventional representation of the solution as a linear combination of basis functions, the DGM takes a novel path by incorporating a deep neural network into its framework. This neural network undergoes training to conform to the requirements of the differential operator as well as the initial and boundary conditions through stochastic gradient descent on randomly sampled time and spatial points. This training process enhances the DGM's ability to provide accurate solutions while circumventing the computational challenges associated with traditional methodologies.

In this blog post I will first explain all the necessarry background information that is necessary to understand to needed concepts. Together, we will have a look at Partial Differential Equations, the Galerkin Method, Stochastic Gradient Descent and Antithetic Sampling. Then I will show the algorithm presented in the paper as well as modifications to it in order to increase the computation speed. And finally, we will describe the experimental results that were made by the authors when testing the DGM algorithm as well as having a look at some theoretical results that the paper provides.

## Partial Differential Equations
Partial Differential Equations (PDEs) stand as the backbone of mathematical modeling, governing phenomena from heat transfer and fluid dynamics to quantum mechanics. These intricate mathematical entities have been pivotal in our quest to understand and predict the behavior of complex systems.

Partial Differential Equations involve functions of multiple variables and their partial derivatives. They play a pivotal role in describing how physical quantities vary with respect to multiple independent variables, such as space and time. The general form of a PDE can be expressed as:

$$F(t, x_1, ..., x_n, u, \frac{\partial u}{\partial t}, \frac{\partial u}{\partial x_1}, ..., \frac{\partial u}{\partial x_n}, \frac{\partial^2 u}{\partial x_{1}^2}, ..., \frac{\partial^2 u}{\partial x_{n}^2},...) = 0$$

Here, $u$ represents the unknown function, and $\frac{\partial u}{\partial t}$ and $\frac{\partial u}{\partial x_i}$​ denote its partial derivatives with respect to time and each spatial variable $x_i$​, respectively.

### Classification of PDEs

Partial Differential Equations (PDEs) can be classified into several categories based on their characteristics and mathematical properties. For once, we can classify them into linear and nonlinear PDEs:
- **Linear PDEs**: The dependent variable and its derivatives appear linearly in the equation. Superposition principle holds, meaning if $u_1$​ and $u_2$ are solutions, then $au_1 + bu_2$​ is also a solution.
- **Nonlinear PDEs**: The dependent variable and its derivatives appear nonlinearly. Superposition principle does not generally hold.

Quasilinear and Fully Nonlinear PDEs:
- **Quasilinear PDEs**: The coefficients of the highest-order derivatives are functions of the dependent variable and lower-order derivatives.
- **Fully Nonlinear PDEs**: The coefficients can depend on both the dependent variable and its derivatives.

We can classify PDEs based on their order:
- **First-Order PDEs**: Involving only first-order partial derivatives.
- **Second-Order PDEs**: Involving second-order partial derivatives.
- And so on

Elliptic, Hyperbolic, and Parabolic PDEs:
- **Elliptic PDEs**: Typically associated with problems of steady-state equilibrium. Examples include Laplace's equation and Poisson's equation.
- **Hyperbolic PDEs**: Associated with problems involving waves and propagating phenomena. Examples include the wave equation and the advection equation.
- **Parabolic PDEs**: Commonly describe problems involving diffusion and time-dependent processes. Examples include the heat equation and the diffusion equation.

Homogeneous and Nonhomogeneous PDEs:
- **Homogeneous PDEs**: When all terms in the equation are functions of the dependent variable and its derivatives.
- **Nonhomogeneous PDEs**: Include additional source or forcing terms that are functions of the independent variables.

### Significance of PDEs

In various scientific, engineering, and environmental domains PDEs occupy a central and expansive role making them an indispensable tool for understanding and optimizing complex systems. One of the primary areas where PDEs wield considerable influence is in the modeling of physical phenomena. They provide a robust mathematical framework for describing the evolution of dynamic systems over both time and space. Whether it be heat conduction, fluid flow, electromagnetic fields, or quantum mechanics, PDEs serve as an essential tool for capturing the intricacies of these phenomena and facilitating a deeper comprehension of their behavior.

In the field of engineering and technology, PDEs play a crucial role in optimizing designs and enhancing the performance of diverse systems. Engineers leverage these equations to simulate real-world scenarios, allowing for the refinement of structures such as bridges, aircraft, and electronic devices. The application of PDEs in engineering not only aids in the conceptualization of designs but also enables the prediction of system behavior under various conditions, contributing to the development of more robust and efficient technologies.

Environmental studies represent another domain where the significance of PDEs becomes apparent. In this context, PDEs are instrumental in modeling and understanding complex processes that have far-reaching implications for the planet. Groundwater flow, air pollution dispersion, and climate dynamics are examples of environmental phenomena that can be effectively studied and analyzed using PDEs. By incorporating these equations into environmental models, scientists can gain valuable insights into the behavior of ecosystems and contribute to the development of sustainable solutions.

Furthermore, the interdisciplinary nature of PDEs allows for their application in a wide range of scientific and technological research. Whether it's predicting the behavior of materials at the nanoscale or simulating the dynamics of biological processes, PDEs provide a versatile and powerful tool for researchers across various disciplines.

Hence, PDEs are of significant use across many fields. Their ability to mathematically represent complex phenomena, simulate real-world scenarios, and contribute to the advancement of diverse areas of research underscores their indispensable role in shaping our understanding of the physical world and optimizing technological and environmental processes.

### Challenges in Solving PDEs

PDEs present intricate challenges in practical applications, with two notable aspects contributing to the complexity of their solution: the critical role of boundary and initial conditions and high dimensionality. The accurate solution of PDEs is contingent upon specifying appropriate boundary and initial conditions. These conditions act as essential constraints that define the behavior of the system over time and space. However, in many practical instances, precisely determining these conditions can be a challening task. Uncertainty or lack of exact knowledge about boundary and initial conditions can introduce ambiguity and compromise the reliability of the obtained solutions. This uncertainty poses a significant challenge, forcing researchers and practitioners to develop robust methodologies for dealing with imprecise or incomplete information regarding boundary and initial conditions.

Furthermore, high dimensionality is a prevalent concern in numerous real-world scenarios involving PDEs, where a large number of variables are inherent in the mathematical representation of dynamic systems. This characteristic results in systems that are high-dimensional, posing computational challenges for traditional numerical methods. The computational complexity grows exponentially with the increase in dimensions, making it necessary to explore innovative computational techniques to efficiently handle such situations.

In this blog post we will explore a deep learning approach that employs a mesh-free algorithm for approximating the solution of a PDE, making it computionally more feasible in higher dimension.

### The reference PDE
In the paper the DGM is applied to the following parabolic PDE. However, the algorithm can easily be modified to other classes of PDEs. Let $[0, T]$ be the time interval and $\Omega$ be the spatial domain of our problem. Then, we can define the differential operator as:

$$ \frac{\partial u}{\partial t}(t, x) + Lu(t,x) = 0 $$ 

with $(t,x) \in [0, T] \times \Omega$. The initial condition is

$$ u(0, x) = u_0(x) $$

for $x \in \Omega$. And, with $\partial \Omega$ being the boundary of the domain $\Omega$, the boundary condition is defined as

$$ u(t, x) = g(t, x) $$

on $(t,x) \in [0, T] \times \partial \Omega$

## A short note on the Galerkin Method
The Galekin method named after the Russian mathematician Boris Galerkin and developed in 1915 is as a numerical approach to solving partial differential equations. It doesn't attempt to find an exact solution to a problem but instead seeks an approximate solution by projecting it onto a finite-dimensional subspace.

At its core, the Galekin method involves choosing a finite-dimensional space of basis functions and determining the coefficients that minimize the residual in the chosen space. With this approach it is possible to transform a rather challenging differential equation into a easier to solve algebraic problem, allowing for efficient computation and approximation.

The algorithm presented in the paper is called "Deep Galerkin Method" (DGM), since it is similar in spirit to the Galerkin method, in the sense that the algorithm tries to approximate the solution of the PDE. But instead of using of using a linear combination of basis functions the DGM uses a deep neural network to satisfy the differential operator, the initial condition and the boundary conditions of the PDE.

## Some general notes on stochastic gradient descent

Stochastic Gradient Descent (SGD) is a powerful optimization algorithm widely employed in machine learning and deep learning for minimizing the loss function during model training. It stands out for its efficiency, especially when dealing with large datasets, as it optimizes the model parameters by updating them incrementally based on a randomly sampled subset of the training data. Key Principles of Stochastic Gradient Descent include :

- ***Random Sampling***: SGD operates by randomly selecting a small batch of data points (mini-batch) from the entire dataset at each iteration. This stochasticity introduces noise into the optimization process, but it also accelerates convergence and reduces computational requirements compared to traditional gradient descent.
    
- ***Incremental Updates***: Unlike batch gradient descent, which computes the gradient of the entire dataset before updating the model parameters, SGD updates the parameters after processing each mini-batch. This incremental approach allows for faster convergence and makes the algorithm well-suited for online learning scenarios.

- ***Efficiency in Large Datasets***: The efficiency of SGD becomes evident when dealing with large datasets. Processing the entire dataset for each iteration can be computationally expensive, and SGD's reliance on random mini-batches significantly speeds up the optimization process.

- ***Learning Rate***: The learning rate is a crucial hyperparameter in SGD that determines the step size during parameter updates. It influences the convergence speed and stability of the optimization process. If we choose the learning rate too small our algorithm might take too long to find a good solution, but if the learning rate is too large we might oscillate around the minimum. Hence, techniques like learning rate schedules and adaptive learning rates are often employed to fine-tune this parameter dynamically.

Furthermore, it is important to keep in mind that SGD might only converge to a local minimum if we have a non-convex problem.

## Antithetic Sampling
Monte Carlo simulations have become indispensable in various fields, from finance and physics to machine learning. These simulations rely on random sampling techniques to approximate complex mathematical models and solve problems that would be otherwise intractable. One such technique that has gained prominence is antithetic sampling – a clever method designed to enhance the efficiency and accuracy of Monte Carlo simulations.

Monte Carlo simulations involve generating numerous random samples to estimate numerical results. Traditional random sampling methods often suffer from variance, leading to imprecise estimations. Antithetic sampling addresses this challenge by introducing a unique twist to the generation of random variables.

Antithetic sampling is grounded in the concept of creating pairs of random variables that exhibit negative correlation. In simple terms, it involves generating a random variable and its "antithetic" counterpart, which has a relationship that counteracts the randomness of the first. This counteraction aims to reduce overall variance, resulting in more accurate and reliable estimates.

But how does it work? Suppose we need to simulate a random variable $X$. With antithetic sampling, we generate another random variable $Y$ such that $Y = -X$. This ensures that the variability in $X$ is counteracted by the opposite variability in $Y$.

The genius of antithetic sampling lies in its ability to reduce variance. By pairing variables in a way that offsets randomness, the overall variance of the simulation decreases. This variance reduction is especially impactful in scenarios where precision is of great importance.

### A bit more formal
Let $X$ be a random variable and we want to estimate $\mathbb{E}(X)$. We can now draw i.i.d. samples $X_1, ..., X_n$ and estimate $\mathbb{E}(X) = \frac{X_1 + ... + X_n}{n}$. This estimator has variance $\frac{Var(X)}{n}$. But if we now draw additional samples $Y_1, ..., Y_n$ and use the estimator $\mathbb{E}(X) = \frac{\frac{X_1 + Y_1}{2} + ... + \frac{X_n + Y_n}{2}}{n}$ it will have the variance 

$$\frac{Var(\frac{X_1 + Y_1}{2}) + ... + Var(\frac{X_n + Y_n}{2})}{n}$$

For readability, let's focus on a specific pair $(X_i, Y_i)$. Its variance is 

$$Var(\frac{X_i + Y_i}{2}) = \frac{1}{4}(Var(X_i) + Var(Y_i) + 2 Cov(X_i, Y_i))$$

Now, we can achieve a variance reduction if $X_i$ and $Y_i$ have $Cov(X_i, Y_i) < 0$. And for that we can use $Y_i = - X_i$. For more information about antithetic sampling I can very much recommend [2].

## The algorithm

Before we dive into the formal defintion of the algorithm, I will first try to give you an intuition about the paper's idea. Consider again our reference PDE. Of course we do not know the exact solution $u(t, x)$ but we can come up with an approximate solution $f(t, x)$. For now, this could be any function that takes the required inputs and outputs a corresponding value. But even though we do not $u$ we can measure how well $f(t, x)$ satisfies the differential operator, initial conditions, and boundary conditions of our PDE. Or in other words, we can measure the error between how $f$ should behave and how it actually does. Furthermore, we can obviously sample random points from our interval $[0, T]$ and our spatial domain $\Omega$. And with that we can use a standard machine learning approach to find an $f(t, x)$ that minimizes the error on the differential operator, initial conditions, and boundary conditions of our PDE: stochastic gradient descent.

In the DGM algorithm we will just sample a lot of points for our domain, calculate the error of $f(t, x)$ with regards to the differential operator, initial conditions, and boundary conditions of our PDE and then take descent steps adjusting our approximate solution until we have minimized the error sufficiently, i.e., until we get really close to the exact solution.

So far, I have described the idea of adjusting our approximate solution $f(t, x)$ to adapt to the PDE conditions. The remaining question is how do we choose a starting function? And if we have one, how do we perform a gradient descent step on it? This is were the ***Neural Network*** comes into play. We can choose an (more or less) arbitrary neural network, represented by its weights parameters $\theta$ as our approximate solution. With that we can easily perform the gradient descent step on the neural network's parameters and repeat this step until we reach a convergence criterion.

So, in essence the DGM algorithm is rather straightforward and let's have a look at the formal definition of it:

### The Deep Galerkin Method

Let $\theta \in \mathbb{R}^k$ represent the parameters of our neural network, let $[0, T]$ be our time interval and let $\Omega \subset \mathbb{R}^d$ be our spatial domain. We write $f(t, x; \theta)$ to denote the function described by our current neural network's parameters. Let's construct our objective function: we need our approximate solution $f$ to satisfy the differential operator, initial conditions, and boundary conditions of our PDE. So, let's break it down into three parts:

For the differential operator we now that $\frac{\partial u}{\partial t}(t, x) + Lu(t,x)$ should equal $0$, so we can just measure how far our approximate solution $f$ deviates from it by using the squared distance:

$$ \lVert \frac{\partial f}{\partial t}(t, x; \theta) + Lf(t,x; \theta) \rVert^{2}_{[0, T] \times \Omega} $$

Furthermore, we can introduce some positive probaility densities $\nu_1, \nu_2, \nu_3$ that will describe the likelihood of the different points in our domain. This will generalise the algorithm to a larger set of problems. Then,

$$\lVert h(y) \rVert^{2}_{N, \nu} = \int_{N} |h(y)|^2 \nu(y)dy$$

Such that we can measure the loss with regards to the differential operator as

$$ \lVert \frac{\partial f}{\partial t}(t, x; \theta) + Lf(t,x; \theta) \rVert^{2}_{[0, T] \times \Omega, \nu_1} $$

For the boundary condition we need that $u(t, x) = g(t, x)$. Hence, we can measure the difference between the target value and the actual value of our approximate solution:

$$ \lVert f(0, x; \theta) - g(t, x) \rVert^{2}_{[0, T] \times \partial \Omega, \nu_2} $$

And the same for our initial condition $u(0, x) = u_0(x)$:

$$ \lVert f(0, x; \theta) - u_0(x) \rVert^{2}_{\Omega, \nu_3} $$

Combining these three components we get our final loss function $J(f)$:

$$J(f) = \lVert \frac{\partial f}{\partial t}(t, x; \theta) + Lf(t,x; \theta) \rVert^{2}_{[0, T] \times \Omega, \nu_1} + \lVert f(t, x; \theta) - g(t, x) \rVert^{2}_{[0, T] \times \partial \Omega, \nu_2} \\ + \lVert f(0, x; \theta) - u_0(x) \rVert^{2}_{\Omega, \nu_3}$$

Now, if we find a $f(t, x; \theta)$ that minimizes the loss $J(f)$ we have found a good approximate solution for our PDE. We could try to directly minimize $J(f)$, however that because computionally inpractial when the number of spatial dimensions $d$ becomes too large. Instead we will use stoachastic gradient descent to minimize the error function. We will sample random points from our domain according to our probability densities $\nu_1, \nu_2, \nu_3$, evaluate the gradient of loss function at these points and use it to perform the gradient descent steps for adjusting our neural network's parameters $\theta$.

So, the DGM algorithm is defined as:

1. We first initialize our neural network's parameters $\theta_0$ and the learing rate $\alpha_0$

2. Then we draw random points $$s_n = \{(t_n, x_n), (\tau_n, z_n), w_n\}$$ from our domain. Here $(t_n, x_n) \in [0, T] \times \Omega$, $(\tau_n, z_n) \in [0, T] \times \partial \Omega$ and $w_n \in \Omega$. The random sampling is performed according to the respective probability densities $\nu_1, \nu_2$ and $ \nu_3$.

2. We calculate the loss of our neural network at the random points. Note that the notation has slightly changed here, but in this blog post I will try to stick to the notation in the paper for the ease of comparing the content of this blogpost to the content of the paper.

$$G(\theta_n, s_n) = (\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + Lf(t_n, x_n; \theta_n) )^{2} + (f(\tau_n, z_n; \theta_n) - g(\tau_n, z_n) )^{2} \\ + (f(0, w_n; \theta_n) - u_0(w_n))^{2}$$

3. Take a descent step: $$\theta_{n+1}= \theta_{n} - \alpha_n \nabla_{\theta}G(\theta_n, s_n)$$ and possibly modify the learing rate $\alpha_n$

4. Repeat step 2 until we reach some convergence criterion

5. Output $\theta_n$

The paper proofs that as we increase the number of iterations $n$ the neural network will converge to a solution, i.e., 

$$ \lim_{n \to \infty} \lVert \nabla_{\theta} J(.; \theta_n) \rVert = 0$$

It is further to note that since the algorithm processes the data points sequentially the convergence rate is unaffacted by a large number of data points. And of course, the upper mentioned notes regarding SGD apply also here.  In particular, one should take into account to adapt the learning rate and the fact that the algoritm might only converge to a local instead of the global minimum. But, that's it in essence, that's the DGM algorithm. Now we will have a look at some modifications to the original algorithm in order to speed up the computation.

## Speeding up the calculation of the second derivates

Increasing the computation speed of an algorihm is always welcome. But what is the major problem of this algorithm with regards to computation speed? It is the computation of the second order derivates in the differential operator $Lf(t, x; \theta)$. Borrowing the example from the paper, if our problem has $d = 200$ dimensions we have to compute $\frac{200 \cdot (201)}{2} \approx 20,000$ second derivatives, which can be expensive with some neural network's architectures. This cost is further increased by the fact that we in fact need need to compute the derivatives of these second order derivates, i.e., third order derivatives for the stochastic gradient descent steps.

Hence, the authors provide a Monte-Carlo approach to approximate the second order derivatives, that can be used in some special cases. Recall the differential operator:

$$Lf(t, x; \theta) = a$$

Let's assume that the sum of the second order derivatives in $Lf(t, x; \theta)$ has the form 

$$\frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x) \sigma_j(x) \frac{\partial^2 f}{\partial x_i x_j}(t, x; \theta)$$

with being a positive definite matrix and $\sigma(x) = (\sigma_1(x), ..., \sigma_d(x))$. Then, it holds that

$$ \frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x) \sigma_j(x) \frac{\partial^2 f}{\partial x_i x_j}(t, x; \theta) = \\ \lim_{\Delta \to 0}\mathbb{E} \left[\sum^d_{i=1} \frac{\frac{\partial f}{\partial x_i}(t, x + \sigma(x)W_{\Delta}; \theta) - \frac{\partial f}{\partial x_i}(t, x; \theta)}{\Delta} \sigma_i(x) W^i_{\Delta} \right] $$

with a convergence rate of $\mathcal{O}(\sqrt{\Delta})$. Here, $W_t \in \mathbb{R}^d$ is a Brownian motion and $\Delta \in \mathbb{R}_{+}$ is the step-size.

We can use this for modifying the algorithm such that it approximates the second order derivatives. In order to do that, let's first split up the upper defined loss function $G(\theta_n, s_n)$ and define:

- $G_1(\theta_n, s_n) = (\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + Lf(t_n, x_n; \theta_n) )^{2}$,

- $G_2(\theta_n, s_n) = (f(\tau_n, z_n; \theta_n) - g(\tau_n, z_n) )^{2}$,

- and $G_3(\theta_n, s_n) = (f(0, w_n; \theta_n) - u_0(w_n))^{2}$

such that $G(\theta_n, s_n) = G_1(\theta_n, s_n) + G_2(\theta_n, s_n) + G_3(\theta_n, s_n)$. Since we need to calculate $\nabla_{\theta}G(\theta_n, s_n)$ in the DGM algorithm we need to compute $\nabla_{\theta}G_1(\theta_n, s_n)$ in particular, which requires to compute the second order derivatives in the differential operator. Hence, we need to find a way to approximate them. For that let's introduce some notation. Define:

$$L_1f(t_n, x_n; \theta_n) = Lf(t_n, x_n; \theta_n) - \frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x_n) \sigma_j(x_n) \frac{\partial^2 f}{\partial x_i x_j}(t_n, x_n; \theta)$$

such that trivially

$$Lf(t_n, x_n; \theta_n) = L_1f(t_n, x_n; \theta_n) + \frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x_n) \sigma_j(x_n) \frac{\partial^2 f}{\partial x_i x_j}(t_n, x_n; \theta)$$

With that we can write $G_1(\theta_n, s_n)$ as

$$G_1(\theta_n, s_n) = \left(\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + L_1f(t_n, x_n; \theta_n) + \frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x_n) \sigma_j(x_n) \frac{\partial^2 f}{\partial x_i x_j}(t_n, x_n; \theta) \right)^{2}$$

Applying the chain rule we can calculate the derivative of $G_1(\theta_n, s_n)$ by

$$\nabla_{\theta} G_1(\theta_n, s_n) = 2\left(\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + L_1f(t_n, x_n; \theta_n) + \frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x_n) \sigma_j(x_n) \frac{\partial^2 f}{\partial x_i x_j}(t_n, x_n; \theta) \right) + \\ \nabla_{\theta} \left(\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + L_1f(t_n, x_n; \theta_n) + \frac{1}{2} \sum^d_{i,j = 1} \rho_{i,j} \sigma_i(x_n) \sigma_j(x_n) \frac{\partial^2 f}{\partial x_i x_j}(t_n, x_n; \theta) \right)$$

Then, finally we approximate $\nabla_{\theta} G_1(\theta_n, s_n)$ as $\widetilde{G_1}(\theta_n, s_n)$:

$$\widetilde{G_1}(\theta_n, s_n) = 2\left(\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + L_1f(t_n, x_n; \theta_n) + \frac{1}{2} \sum^d_{i=1} \frac{\frac{\partial f}{\partial x_i}(t_n, x_n + \sigma(x_n)W_{\Delta}; \theta_n) - \frac{\partial f}{\partial x_i}(t_n, x_n; \theta_n)}{\Delta} \sigma_i(x_n) W^i_{\Delta} \right) + \\ \nabla_{\theta} \left(\frac{\partial f}{\partial t}(t_n, x_n; \theta_n) + L_1f(t_n, x_n; \theta_n) + \sum^d_{i=1} \frac{\frac{\partial f}{\partial x_i}(t_n, x_n + \sigma(x_n)\widetilde{W}_{\Delta}; \theta_n) - \frac{\partial f}{\partial x_i}(t_n, x_n; \theta_n)}{\Delta} \sigma_i(x_n) \widetilde{W}^i_{\Delta} \right)$$

Again, $W_{\Delta}$ and $\widetilde{W}^i_{\Delta}$ are two i.i.d. $d$-dimensional normal random variable with $\mathbb{E}[W_{\Delta}] = 0$ and with the covariance between the $i$-th and the $j$-th entry of $W_{\Delta}$ being $\rho_{i,j} \Delta$.

With this Monte Carlo scheme we can increase the algorithms speed, however, we introduce a bias of $\mathcal{O}(\sqrt{\Delta})$ into the calculation of $\nabla_{\theta}G_1(\theta_n, s_n)$.

### Reducing the approximation error
- Show approximation bias, approximation error $\mathcal{O}(\Delta)$
- Describe the modified algorithm

## Numerical Analysis

Here we discuss the numerical results of the algorithm.

The algorithm is tested on
- High-dimensional Free Boundary PDE
- High-dimensional Hamilton-Jacobi-Bellman PDE
- Burgers’ equation

The discussion of the experiments is structured as 
- Define the PDE
- Adjust the algorithm to the specific problem
- Implementation details
- Results

## Neural Network Approximation Theorem for PDEs

Besides explaining and testing the DGM algorithm the paper also provide some theoretical results regarding the approximation of the PDE solution through the neural network. The authors prove that the neural network used in the DGM converges to the exact solution of the PDE with an increasing number of hidden units of the neural network. Let's describe the results:

We have our measurement $J(f)$ that measures how well our neural network (denoted by $f$) approximates the PDE solution. Now we also have $C^n$, a set of neural networks, each with a different number of hidden units. In this set, there's a best element, $f^n$, a neural network with $n$ hidden units, that does the best job at minimizing the approximation error. As we let the number of hidden units ($n$) grow, the error of our best neural network ($J(f^n)$) becomes almost non-existent. In mathematical terms, $J(f^n)$ shrinks to zero as $n$ goes to infinity ($J(f^n) \rightarrow 0$  as $n \rightarrow \infty$). However, not only does the error of $f^n$ get very close to $0$, but $f^n$ also gets closer and closer to the actual solution of the PDE.

Now, in mathematical terms: the authors define $C^n$ as the class of neural networks with a single hidden layer and $n$ hidden units. Furthermore, let $f^n \in C^n$ be a neural network with $n$ hidden units which minimizes the error $J(f)$. Under certain technical conditions, the authors prove that

there exists $f^n \in C^n$ such that $J(f^n) \rightarrow 0$, as $n \rightarrow \infty$, and

$f^n \rightarrow u$ as $n \rightarrow \infty$.

For the actual proofs, the interested reader is referred the paper, as they describe it in great detail.

## Conclusion

Partial Differential Equations serve as the mathematical language that allows us to articulate and comprehend the complex dynamics of the world around us. As we push the boundaries of technology and scientific inquiry, innovative methods and interdisciplinary collaborations continue to reshape our approach to solving and understanding PDEs. In this blog post about the paper *'DGM: A deep learning algorithm for solving partial differential equations'* by Justin Sirignano and Konstantinos Spiliopoulos I looked at the Deep Galerkin Method, a new approach for approximating the solution of a PDE.

The DGM presents a promising idea for efficiently solving high-dimensional PDEs without relying on a traditional mesh-based method. This makes the DGM computionally more tractable as the number of dimensions of the PDE increases. Its application to diverse problems and the theoretical foundation laid out in this post demonstrate its potential impact. The DGM employs a deep neural network in order to satisfy the differential operator, initial conditions, and boundary conditions of the PDE using stochastic gradient descent on randomly sampled time and spatial points.

Future research ideas made by the authors include exploring further improvements in computational efficiency and the extension of the method to different types of PDEs like hyperbolic, elliptic or partial-integral differential equations.

I hope this blog post did its job of explaining the ideas presented in the paper intuitively as well as on a algorithmic level. The DGM in essence is a rather straightforward approach for approximating PDEs compared to some other methods (think of your class on scientific computing), but I believe that that just makes it more interesting (and of course the numerical results showcase that the found solution is indeed a good one). I am happy to receive some feedback and if there are any questions about the blog post you can write me an E-Mail and I will try to answer it as fast as I can. Until then, thanks for reading!

## References

[1] Sirignano, J., Spiliopoulos, K. (2018). *DGM: A deep learning algorithm for solving partial differential equations*. [arXiv: 1708.07469](https://arxiv.org/abs/1708.07469)

[2] S. Asmussen and P. Glynn, Stochastic Simulation: Algorithms and Analysis, Springer, 2007.
